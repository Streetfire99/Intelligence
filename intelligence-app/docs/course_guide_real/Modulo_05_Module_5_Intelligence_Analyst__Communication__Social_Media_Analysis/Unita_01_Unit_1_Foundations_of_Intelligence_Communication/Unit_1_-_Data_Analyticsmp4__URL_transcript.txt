Buongiorno e benvenuti nel modulo 1 Data Analytics and Risk che è un modulo relato alla data analisi e all'analisi del rischio in un campo specifico dell'intelligenza del business e all'analisi del rischio nei paesi e nella situazione economica Quindi, la razione del modulo è considerare le fondazioni teoretiche e pratiche della data analitica in questo contesto dove l'applicazione è chiara all'intelligenza e all'analisi del rischio per il business In questo senso, il tipo di data tipico è una data particolare che può essere capiente molto bene e dobbiamo concentrarci sui diversi ranghi di metodi analitici che possono essere usati per l'analisi e la gestione del rischio e dei problemi sistemici del business In questo senso, dobbiamo usare metodologie dove l'idea finale è l'applicazione di decisioni strategiche migliori in specifici contesti e ambienti In questo senso, è possibile considerare questo tipo di analisi molto importante per l'analisi del rischio in cui è possibile assessare i potenziali tratti e le vulnerabilità che sono parte dei sistemi moderni e questo tipo di problemi può imparare a un paese stabilito e sicuro. In questo senso, l'analisi del rischio e il processo di scoprire questo tipo di problemi possono avere un effetto specifico che ci permette di identificare diversi rischi politici, economici e social o ambientali Ovviamente, in questo corso, vogliamo essere molto pratici e specifici in questo senso, non siamo interessati alle visioni teoretiche che possiamo considerare in politica, economica, sociale e ambientale, ma vogliamo scoprire alcune metodologie che possiamo usare per definire quali sono i specifici consigli e ricomendazioni per i decisionisti. Quindi, il nostro interesse specifico è il fatto che è possibile ottenere alcuni risultati relevanti che possiamo usare dai decisionisti per mitigare questo tipo di rischio effettivamente In questo senso, l'obiettivo qui è identificare i metodi appropriati della data analitica e quattro sono gli elementi rilevanti che possiamo considerare In effetti, l'analisi del rischio e l'intelligenza è basata su quattro framework interessanti Il primo framework è le tensioni sociali, quindi è possibile considerare quali sono le tensioni sociali che esistono nella popolazione, ma allo stesso tempo esistono anche le instabilità politiche Le tensioni sociali sono per esempio relazioni con i dati che possiamo raccogliere su diversi siti web politici, come per esempio strisci o anche il sentimento della popolazione relazionato ai diversi elementi problemi che sono relazionati a un legame specifico e così via La instabilità politica è chiaramente relazionata all'esistenza di diversi governamenti che sono instabili e allo stesso tempo è possibile trovare questo tipo di dati in diversi siti web in diversi modi, quindi in questo senso tutti questi tipi di dati devono essere raccogliti su diversi database e poi essere specificamente mescolati in una database unica In questo senso, una suggestione può essere usata in modo da creare diverse tabelle con diversi specifici dati, blocchi di dati per la tensione sociale, la stabilità politica e così via e poi analizzare i dati finali. Inoltre, i rischi ambientali sono molto importanti perché possono essere relazionati a diversi elementi come gli accadimenti o altre cose che possono avere un grande impatto e in questo senso è molto importante analizzare questi tipi di dati che possono essere raccogliti in diversi modi e in questo senso possono essere raccogliti in diversi database e in diversi tipi di fonti Finalmente, le fluttuazioni economiche sono l'unica fonte tipica di dati che può essere rilevante l'economia è un elemento tipico che può essere analizzato in un paese relativo all'analisi dei rischi dei costi e così via Le fluttuazioni economiche possono essere relazionate al fatto che i cicli di azienda tendono a avere un ciclo e in questo senso è molto importante prevedere questo tipo di dati in modo che possano essere utili per le firme, utili per l'intelligenza e utili per l'intelligenza di un'azienda In pratica esistono tre livelli di analitica che possono essere relazionati ai rischi ma in generale l'analitica è relazionata a tre livelli specifici Esiste il primo livello che è relazionato alla descrizione dell'analitica, che è molto importante perché a volte vogliamo solo permettere che i nostri dati possano mostrarti un po' di fotografia dei nostri dati e la descrizione dell'analitica è importante perché sommarizzare i nostri dati con un obiettivo specifico per identificare alcuni pattini e alcune tendenze Anche se siamo interessati a fornire alcuni dati dobbiamo usare l'analitica predittiva L'analitica predittiva è aiutata ad identificare le azioni ottimali basate su consigli predittivi e risultati ma anche su dei constrinti definiti In questo senso l'analitica predittiva è basata sulla simulazione quindi non usiamo solo l'analisi di dati ma possiamo considerare un modello più complesso in cui possiamo identificare con l'analisi di dati alcune azioni ottimali che possiamo usare In questo senso, dove l'analitica predittiva è tipica per fotografiare i nostri dati e l'analitica predittiva permette di creare un forecast l'analitica prescrittiva può identificare azioni ottimali e con un forecast possiamo considerare un'altra strategia su un altro paese quindi possiamo prevedere un comportamento di un agente che è involto nella nostra analisi l'analitica prescrittiva permette di creare una strategia più complessa basata su problemi strategici e consigli predittivi in questo senso possono essere molto utili per essere considerati insieme le tipologie di dati possono essere molto diverse dipendendo dall'applicazione dobbiamo considerare possiamo considerare diversi tipi di dati come per esempio i dati cross-sectionali i dati cross-sectionali sono dei dati tipici che sono coltivati per stare e per fare una foto di oggi quindi consideriamo i dati a tempo T una serie di tempi per un gruppo di paesi o un gruppo di regioni o un gruppo di unità geografiche e statistiche è molto importante considerare che i dati cross-sectionali sono molto rilevanti per fare una comparazione perché in questo senso consideriamo diversi unità statistiche e possiamo considerare una comparazione di diversi dati i dati a tempo T sono relati a una singola variabile che viene seguita con il tempo e consideriamo questo tipo di dati in loro evoluzione quindi i dati a tempo T sono molto importanti perché in molti casi la nostra analisi di rischio ha una dimensione temporale molto importante quindi per considerare la dimensione temporale possiamo considerare questo tipo di dati e le forecast tipicamente sono in un certo senso relati ai dati a tempo quindi in questo senso i dati a tempo T sono molto importanti perché permettono di prendere in accanto queste specifiche considerazioni quindi i dati a tempo T possono essere orientati a predicazioni a forecasting dove i dati cross-sectionali sono più orientati a una sorta di comparazione i dati a tempo T sono dati che combinano l'aspetto l'effetto cross-sectionale cioè il fatto che abbiamo diversi unità statistiche a tempo T ma allo stesso tempo la dimensione temporale quindi abbiamo diversi unità statistiche e possiamo studiare la dinamica del tempo e il comportamento del tempo in questo senso le tipiche differenti metodologie possono essere considerate per diversi tipi di dati dove è possibile esplicitamente usare una metodologia per forecasting con dati a tempo T un'altra metodologia può essere usata in dati cross-sectionali e questo è il punto di partenza della nostra analisi in cui colleghiamo i dati ad esempio qui in un contesto geografico che può essere considerato molto importante perché possiamo considerare specificamente qualche variazione sociale che possiamo considerare come rilevante per analizzare e per poter descrivere il rischio e le caratteristiche che esistono per i diversi paesi o nazioni o regioni in questo senso c'è un esempio in cui possiamo vedere e osservare diversi Stati USA e diverse caratteristiche che ci permettono di analizzare alcuni rischi che accadono in questo senso questa è la tipica matrica di dati ovviamente possiamo usare diversi tipi di dati ma questo è ciò che facciamo esplicitamente iniziamo da diversi fondi colleghiamo i dati in un database e poi usiamo una specifica matrica di dati che è il nostro punto di partenza ma quali sono i diversi dati possono essere considerati in due differenti specifici contesti che sono piccoli dati o dati tipici che sono usati in molte diverse applicazioni e usano strumenti tradizionali in un certo senso più semplici e più diretti e semplici perché sono tipicamente di volume più bassi, ben strutturati e sono usciti per specifici ipotesi in questo senso l'idea è di iniziare da una domanda statistica ma questi tipi di dati sono tipici dei dati gestibili e possono essere più semplici per essere puliti, analizzati e interpretati dove abbiamo, ed è un problema degli ultimi anni quando abbiamo dati grandi possiamo considerare in effetti i dati grandi tendono a essere estremamente grandi e complessi i dati che non possono essere gestiti con metodi tradizionali e poi è necessario considerare volume, velocità, diversità, verità e valore che sono le caratteristiche dei dati grandi in volume velocità diversità verità e valore queste sono le caratteristiche che sono molto importanti su i 5V dei dati grandi in quale modo possiamo considerare i dati grandi in pratica? ci sono alcune metodologie come l'analisi simbolica che possiamo usare nell'analisi di dati grandi altre possibilità sono ovviamente i dati simbolici i dati simbolici i dati simbolici

per dividere e stampare i dati, in questo senso l'uso della popolazione e dei sampli può essere un modo molto utile per approcciare con il Big Data, ma esiste allo stesso tempo, come ho menzionato, la simbolica analisi, altre tipologie che possono essere usate per la Big Data analisi. Allo stesso tempo esistono diversi strumenti analitici e ovviamente ci sono molti, molti, molti strumenti R, Python, Julia, Octave e altri. R, Python, Julia e Octave sono gratis, quindi non c'è bisogno di pagare per acquistare il software. Altri possono essere collegati a altri strumenti analitici che sono commerciali, e in effetti esistono altri strumenti che possono essere considerati per l'analisi, ma sono strumenti che possono essere molto diversi, perché ovviamente ogni software ha differenti caratteristiche. Se R e Octave sono utili per diversi tipi di analisi e R è il programma di lingua più generale che possiamo considerare per l'analisi, dove Python è una lingua specifica che possiamo usare anche per l'intelligenza artificiale e molti metodologi diversi nell'intelligenza artificiale, dove R è più relato all'analisi, all'analisi classica, esistono molti strumenti che possono essere considerati per l'analisi di dati. Stata, per esempio, è forte per l'analisi di dati sul pannello e anche per l'analisi di dati cross-sectionale, mentre AViews è anche più forte quando è necessario considerare l'analisi di tempo serie. Tableau ha una possibilità molto relevante per creare l'analisi grafica, quindi è molto rilevante per l'analisi di dati esploratori e grafici, mentre Gradle ha alcune caratteristiche di AViews, ma è anche gratuito. In questo senso, dove ci sono le caratteristiche di R, Python e Octave, in cui l'interfaccia user grafica non è così ben considerata e è necessario usare altri strumenti come RStudio e così via, Gradle, come interfaccia user grafica nativa, può essere utile per l'analisi di dati. Ovviamente, c'è una strategia nell'analisi di dati che è ben definita in questo modo. Definizione del problema d'investigazione, collezione di dati, preprocessing, analisi di dati, analisi di sensibilità e disseminazione o riportaggio. Molte analisi non richiedono tutte queste fasi diverse. Ad esempio, nell'analisi di sensibilità, in alcuni casi può essere usato, ma in altri non è così rilevante, ma è utile e rilevante prendere in accanto la sensibilità su alcune decisioni. Quindi, se decidiamo di fare una decisione sull'imputazione di dati, dobbiamo sapere se c'è un impatto sui risultati finali. Questo è l'obiettivo specifico dell'analisi di sensibilità. Ma è molto importante la definizione del problema d'investigazione. E' molto rilevante per un'analista definire al meglio il problema e il modo in cui il problema può essere investigato. In questo senso, il problema di investigazione non dovrebbe essere capito molto bene. Anche per la collezione di dati, abbiamo già visto la costruzione della matrice, il preprocessing è una parte molto importante perché può essere considerato un modo per preanalizzare correttamente i dati e poterli usare esplicitamente. In effetti, i dati, i dati del paese e i dati tipici di questo framework possono avere problemi. I problemi possono essere i dati scassati, possono essere dati senza base, quindi c'è una specifica osservazione che è molto alta o molto bassa e in questo senso è molto importante prendere in contatto le differenti caratteristiche dei dati per gestire appropriatamente questo tipo di dati. Questa è la pipelina tipica in cui iniziamo dal problema dell'investigazione poi continuiamo con la collezione di dati continuiamo con il preprocessing poi andiamo all'analisi, l'analisi di sensibilità, la disseminazione e il riportaggio dei diversi risultati. Cos'è il problema dell'investigazione e perché è così importante? Il problema dell'investigazione è il problema specifico che dobbiamo considerare. In questo senso dobbiamo identificare il problema che vogliamo risolvere con l'analisi di dati che è ovviamente relato al rischio, che è ovviamente relato all'intelligenza e possibilmente alla situazione in diversi paesi ma il problema deve essere stato dall'analista molto precisamente e poi i dati devono essere collezionati come rilevanti alla risoluzione del problema da considerare. In questo senso deve essere scelto una metodologia rilevante per risolvere il problema. Quindi in questo senso un primo passaggio è anche mettere una domanda statistica o quantitativa. Se l'idea è trovare se l'averaggio dei prezzi è uguale per un gruppo di paesi a T e T più 1 o più 2 quindi vogliamo sapere se i prezzi per diversi paesi come un minimo o un averaggio è cambiato in questo senso dobbiamo creare un'ipotesi. Quindi in questo senso l'investigazione del problema dovrebbe essere messa in modo per essere analizzata come ipotesi. In questo senso le ipotesi possono essere molto importanti quindi in questo senso le ipotesi sono fondamentali per capire esattamente cosa dobbiamo fare. Allo stesso tempo la fase di ricerca dei dati è molto rilevante in ogni progetto di ricerca e in questo senso è possibile considerare e raccogliere i dati diversi e rilevanti su tutti i problemi che possiamo considerare. In questo senso i dati dovrebbero essere rilevanti in ogni progetto di ricerca ma è necessario creare i dati rilevanti per poterli usare nell'analisi dei dati. E in questo senso in molti casi l'importante è decidere se i dati sono una popolazione specifica quindi consideriamo tutti i dati che prendiamo in considerazione dal problema che vogliamo considerare o abbiamo solo un esempio quindi possiamo creare un design, un design di esempio in cui possiamo considerare un esempio che in molti casi dovrebbe essere un esempio rando e un esempio rando ma rappresentativo dei nostri dati come popolazione. Perché esempio rando? Perché rappresentativo? Perché il metodologo statistico l'inferenza statistica potrebbe essere assolutamente bene solo per i dati che sono un esempio rando quindi possiamo generalizzare il risultato da un esempio a una popolazione solo se stiamo considerando un esempio rando e un esempio rappresentativo della popolazione Anche la fase di preprocessing è molto rilevante perché i dati sono tipicamente caratterizzati la maggior parte del tempo da incompletità e problemi generali come l'errore quindi in questo senso è importante considerare un'analisi di qualità in cui per esempio la pulizia dei dati è importante la pulizia dei dati significa editare valori scassati o anche escludere valori scassati correggendo errori o no o solo identificando errori ma allo stesso tempo rimuovendo duplicate erronee questo è molto importante per la pulizia dei dati quindi i dati non sono assolutamente corretti in un senso perfetto ma devono essere esplorati per identificare problemi che possono succedere Anche la trasformazione può essere importante perché in molti casi è utile considerare un formato o una struttura che sia adatta all'analisi Anche la selezione dei dati può essere importante perché permettono di identificare trasformazioni come per esempio la creazione di indicatori compositi o l'uso di altri metodologi possiamo combinare i dati in indicatori nuovi che sono più prevedibili o possiamo essere più specifici o possono essere codificati in modo diverso per esempio possiamo creare un variabile per l'intelligenza e quindi dobbiamo misurare, estimare l'intelligenza usando differenti caratteristiche o possiamo considerare nell'analisi di rischio alcune variabili latenti che possono non essere osservate direttamente e quindi possiamo considerare variabili diverse per misurare questo tipo di variabili l'analisi è ovviamente rilevante, possiamo considerare le diverse metodologie per ottenere risultati mentre l'analisi di sensibilità è importante anche perché vogliamo assessare l'incertezza della variabile d'entrata e allo stesso tempo voglio identificare le variabili che possono avere l'influenza più grande sulle predicazioni dei modelli e sui risultati analitici Anche così, l'analisi di sensibilità è importante per migliorare la robustezza dei modelli ma anche la trasparenza della qualità della decisione che si considera. In questo senso il scopo di questo modulo era di introdurre rischi di analisi e analitiche di dati per rischi di analisi considerando le approcci più rilevanti della metodologia di Moore's law che devono essere considerate in questo contesto e in particolare quali sono gli approcci differenti alle analitiche di dati considerando cosa un analista tipicamente fa in questo senso. Per prima cosa definiamo il problema e definiamo alcune domande statistiche alcune domande quantitative per considerare i dati. Poi collezioniamo i dati i dati possono essere popolazione o possono essere un esempio in molti casi ci può essere la necessità di usare un esempio da una popolazione un esempio che può essere un esempio rappresentativo ma allo stesso tempo random la collezione diventa un set di dati una matrica di dati un'analisi di dati quindi è applicata la metodologia giusta, poi i risultati diversi sono analizzati usando l'analisi di sensibilità quindi quando i dati sono analizzati per capire la qualità dei dati che è molto importante e la processazione di dati è una delle fasi più rilevanti che possiamo considerare poi l'analisi di dati può essere esplicitamente analizzata usando diversi metodi di sensibilità che possono per esempio capire l'impatto di una variazione su un'altra finalmente la decisione o una idea specifica che possiamo usare per l'analisi prescrittiva ma sicuramente in questo modo possiamo avere un'idea dal risultato, dalla soluzione della domanda che abbiamo al problema che abbiamo considerato all'inizio ok, questo è il primo modulo in seguito discuteremo su diverse metodologie che possiamo considerare in questo contesto grazie per l'attenzione