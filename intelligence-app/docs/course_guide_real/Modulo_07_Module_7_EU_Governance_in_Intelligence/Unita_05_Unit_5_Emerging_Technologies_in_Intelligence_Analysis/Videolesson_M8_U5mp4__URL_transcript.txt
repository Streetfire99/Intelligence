Welcome to Unit 5 of Module 8, EU Governance in Intelligence in the framework of the Massive Open Online Course within the Analyst Project, a new advanced level for EU specialized training. In this part of the course, in Unit 5, we are diving into the world of emerging technologies and their growing impact on intelligence analysis. We will explore how tools like artificial intelligence, blockchain, big data and biometric surveillance are transforming the way intelligence is gathered, analyzed and used in decision making. So, in the four parts that we see in the Table of Contents, we will focus on AI and machine learning, then on blockchain for secure intelligence sharing. Third part will be focusing on big data analytics in threat predictions and the last part will be on the future of intelligence technologies. We will also look at the ethical and legal concerns that come with these innovations because new capabilities always bring new risks. By the end of the unit, you will be able to identify how technologies are being applied in intelligence contexts, evaluate both their benefits and limitations and consider what safeguards are needed to keep intelligence effective, secure and aligned with democratic values. The use of artificial intelligence for intelligence gathering, analysis and decision support. So here we focus on AI, which allows agencies to process massive volumes of data from sources like CCTV, social media, satellite feeds and digital communications. This automation helps identify patterns or threats that would be missed in manual reviews. AI systems can scan huge volumes of data faster and more accurately than any human analyst. They can identify patterns, flag anomalies and generate predictions in real time. In intelligence, this means quicker detection of threats, better assessment of risk and faster support for decisions in everything from counter-terrorism to migration policy. AI can also automate some of the repetitive or data-heavy tasks that used to slow down analysts, freeing them up to focus on strategy and insight. But the use of AI also raises questions about bias, transparency and control. So that's something we'll return to shortly. Analysts now rely a lot on AI to augment, to increase their efficiency, but not to replace strategic thinking. So this is very important to remember that it cannot replace humans in 100%. It can only increase their efficiency. AI is not just a tool for civilians or control. It's also a force for stability. The United Nations are exploring how AI can support its work in peace and security from conflict prevention to crisis response, while also calling for strong international regulation and ethical standards. If you want to see more on the UN's actions and their approach to AI in global security, you can watch this YouTube video. Just pause this video, this presentation, and click on the link to visit the YouTube video. In AI for peace and security, it can help monitor ceasefires, it can map conflict zones, and even meditate in peace-building processes by analyzing sentiment and detecting early warning signals in online spaces. AI-powered satellite imaging and predictive analytics are already being used to track violence, displacement, and political unrest. In the EU context, AI supports missions under the common security and defense policy by improving situational awareness and mission planning. So used ethically, AI really can become a powerful ally in preventing conflict and promoting peace. Ethically speaking, we need to see this also from this perspective. As we know, as the well-known saying says, with great power comes great responsibilities, and AI in intelligence is no exception. New technologies like this always bring significant ethical risks. These systems can operate with limited transparency and can unintentionally reinforce harmful biases. So the concerns are those algorithmic bias, which could implicate discrimination against certain groups in profiling, the lack of explainability, so analysts may not understand how AI reached a result. So all those technologies need to be more and more developed and explored to have a clearer vision of how it works. Data misuse, so here the implication could be the breaches of privacy and surveillance abuse, and accountability gaps, that it is unclear who is responsible for AI-generated errors. So always remember that you cannot trust AI. It, like I said before, it can enhance productivity and efficiency in day-to-day processes, but it cannot be a replacement for critical thinking. Blockchain is another emerging technology making its way into intelligence. At its core, blockchain is a distributed ledger. It records transactions or data entries in a way that it's secure, verifiable, and very difficult to tamper with. It offers decentralized, tamper-proof, it offers decentralized, tamper-proof systems for storing and sharing intelligence data across agencies or borders. Each transaction or data entry is recorded with a unique hash and timestamp, making it verifiable. It allows controlled access to sensitive data, provides immutable logs for auditing and tracking who accessed what, reduces the risk of insider manipulation, and streamlines secure sharing between trusted parties, such as Europol and Frontex that were discussed in previous units. If you want to repeat this content, go to units one and two. In intelligence, this all could mean more secure sharing of classified information. It can also support digital identity systems and secure authentication for analysts working across agencies or countries. And used correctly, blockchain can really enhance both the integrity and the trustworthiness of intelligence operation. The EU sees emerging technologies not just as tools, but as strategic assets. Artificial intelligence and blockchain are transforming Europe's public sector by enabling more secure data management, improving digital trust, and supporting cross-border cooperation in key areas like security and governance. Please do make a short break to visit this website to read this report about the artificial intelligence, blockchain, and the future of Europe, how disruptive technologies create opportunities for a green and digital economy. This report will help you understand how these technologies are shaping the EU's future in digital infrastructure and public service innovation. Okay. Despite its promise, blockchain is not a silver bullet. One major limitation is scalability. Blockchain

can be slow and expensive to maintain at a larger scale. Data privacy could lead, could implicate immutable records, conflict with rights to be forgotten laws. The complexity could also be a very limiting aspect because blockchain requires technical expertise and aligned protocols. And there's always the question of legal uncertainty because it varies across each EU member state, which is a big risk of inconsistency. So all agencies, national agencies, but also EU agencies must assess whether blockchain adds value or states new risks. Right, we now live in a world of data abundance. Intelligence agencies must not just collect information but make sense of it. So trends in predictive analytics are shaped by the challenges analysts face when using data to detect threats early. And these show how complex risks are turned into patterns that can be tracked early. So here we have a list of challenges and responses to those. A challenge can be hidden radicalization in online forums. A possible response could be using machine learning to map hotspots and trends. Illicit money flows is a very big challenge, but it is very important to trace financial transactions across systems, which will be possible with data-driven intelligence. The movement of high-risk individuals, this can be analyzed with geotagged travel data. And also there is the challenge of extremist communication, but there you can deploy NLP to scan for trigger phrases and sentiment shifts. So that's where data-driven intelligence and predictive analytics come in. By analyzing structured and unstructured data from satellite feeds to social media, analysts can really detect trends, forecast risks, prioritize resources more effectively. For example, predictive models can help anticipate migration flows, identify potential hotspots for conflict or detect disinformation campaigns before they go viral. But with these capabilities also comes the need for careful validation, transparency, and respect for privacy, as we saw in the previous slides. Here we come back to GDPR and the whole aspect of privacy and transparency. Again, to focus on this example of the Paris attacks in 2015, French intelligence services began using AI after the attacks to monitor online activity and detect signs of radicalization. Algorithms scanned social media for extremist content, mapped suspicious networks, and flagged individuals based on behavioral patterns. So these tools helped to disrupt recruitment and funding operations. However, concerns emerged around privacy, profiling, and errors, as sparking public debate about oversights and safeguards. Here is an additional link if you are interested on how AI is used in detecting and preventing radicalization in Europe. It's a report from the International Center for Counterterrorism. So if you are interested in further reading, please pause this video and visit this link. So these tools, we also always need to remember, it helps, AI helps fuse multiple data sources, like travel records, financial data, biometric info, into a single usable picture, but these tools don't replace human judgment. So we need to always remember that. They significantly enhance the ability to act early and effectively, but they cannot replace human critical thinking. Now let's focus on the last part of this unit, the future of intelligence technologies. Those technologies are evolving very rapidly. We have four main aspects, advancements, especially in biometrics and automated intelligence. So we have the facial recognition, which is identifying individuals in real time at airports, large public events, or border checkpoints to flag persons of interest or track movement patterns. We have the biometric scanners, verifying identity through voice, iris, fingerprint, or gait analysis in secure facilities, intelligence operations, or remote border checks. Then we have the autonomous systems, which are deploying AI-powered drones or unmanned vehicles for surveillance, patrolling borders, or monitoring high-risk zones without direct human control, which definitely enhances efficiency and detailed control. And behavioral tracking, which is monitoring body language, gestures, or walking patterns to detect unusual behavior in crowds or to identify potential threats before they act. So as we see, the technological advances have dramatically expanded what surveillance can do. These capabilities raise important legal and ethical questions, such as who has access to all this, how long is this data stored, and what oversight exists. The future of intelligence will depend not only on what is possible, but also on what is permitted. So again, what is permitted again, we need to be very careful with the possibilities, but also with the rights and risks of these rapidly evolving technologies. Now, let's focus on these exact potential risks and legal considerations for new intelligence tools and for the evolving technologies. Emerging surveillance tools challenge traditional legal frameworks. So here we have the risk of invasion of privacy through unwarranted biometrical collection, misidentification leading to wrongful targeting or arrest, lack of oversight on data retention and access, mission creep, tools designed for border security used on civilians. And the legal response is the one that we have already focused on in previous slides and units, the EU's GDPR regulations and the proposed AI Act regulate the personal data use. And then we have national laws that vary from country to country. So here the legal harmonization is still in progress. So here we must consider the legal and societal risks that come with new technology. Surveillance tools can be misused. Data can be breached. Algorithms can make mistakes with real human consequences. So that's why a legal framework must evolve alongside those technological capabilities. In the EU, this means strengthening data protection, ensuring judicial oversight and clarifying the rules of engagement for cross-border intelligence activities. So ultimately new tools must serve democratic goals, but not on top of that, but not undermine them. Innovation in intelligence must go hand in hand with integrity, transparency, and the rule of law. To strengthen your knowledge, please pause this video and choose one topic and do a short reflection on what you have learned and what lesson you can draw from this unit. Thank you very much.